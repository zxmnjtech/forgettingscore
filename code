import os
from math import ceil
from ast import literal_eval
from shutil import copyfile
import json
import glob
import numpy as np
import Parallel_Model
# from module import *
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from python_speech_features import sigproc, fbank, logfbank
from torch.utils.data import Dataset, DataLoader
import numpy as np
import librosa.display
from tqdm import tqdm
import glob
import os
import pickle
import random
import time
import math
import logging
import datetime
import pandas as pd
from warnings import simplefilter

# 创建一个test文件
def createjson(path,path1):
    jsondict ={}
    path_wav = path.rstrip('/')
    wav_files = glob.glob(path_wav + '/*.wav')
    for wavnamet in wav_files:
        name=wavnamet[22:]
        jsondict[name] = 0
    with open(path1, "w") as w:
        w.write(str(jsondict))

class FeatureExtractor(object):
        def __init__(self, rate):
            self.rate = rate

        def get_features(self, features_to_use, X):
            X_features = None
            accepted_features_to_use = ("logfbank", 'mfcc', 'fbank', 'melspectrogram', 'spectrogram', 'pase')
            if features_to_use not in accepted_features_to_use:
                raise NotImplementedError("{} not in {}!".format(features_to_use, accepted_features_to_use))
            if features_to_use in ('logfbank'):
                X_features = self.get_logfbank(X)
            if features_to_use in ('mfcc', 26):
                X_features = self.get_mfcc(X)
            if features_to_use in ('fbank'):
                X_features = self.get_fbank(X)
            if features_to_use in ('melspectrogram'):
                X_features = self.get_melspectrogram(X)
            if features_to_use in ('spectrogram'):
                X_features = self.get_spectrogram(X)
            if features_to_use in ('pase'):
                X_features = self.get_Pase(X)
            return X_features

        def get_logfbank(self, X):
            def _get_logfbank(x):
                out = logfbank(signal=x, samplerate=self.rate, winlen=0.040, winstep=0.010, nfft=1024, highfreq=4000,
                               nfilt=40)
                return out

            X_features = np.apply_along_axis(_get_logfbank, 1, X)
            return X_features

        def get_mfcc(self, X, n_mfcc=40):
            def _get_mfcc(x):
                mfcc_data = librosa.feature.mfcc(x, sr=self.rate, n_mfcc=n_mfcc)
                return mfcc_data

            X_features = np.apply_along_axis(_get_mfcc, 1, X)
            return X_features

        def get_fbank(self, X):
            def _get_fbank(x):
                out, _ = fbank(signal=x, samplerate=self.rate, winlen=0.040, winstep=0.010, nfft=1024)
                return out

            X_features = np.apply_along_axis(_get_fbank, 1, X)
            return X_features

        def get_melspectrogram(self, X):
            def _get_melspectrogram(x):
                mel = librosa.feature.melspectrogram(y=x, sr=self.rate)
                mel = np.log10(mel + 1e-10)
                return mel

            X_features = np.apply_along_axis(_get_melspectrogram, 1, X)
            return X_features

        def get_spectrogram(self, X):
            def _get_spectrogram(x):
                frames = sigproc.framesig(x, 640, 160)
                out = sigproc.logpowspec(frames, NFFT=3198)
                out = out.swapaxes(0, 1)
                return out[:][:400]

            X_features = np.apply_along_axis(_get_spectrogram, 1, X)
            return X_features

        def get_Pase(self, X):
            return X

# 针对测试数据
def wavpth(pathtest,pthpath,jsonpath):
    path_wav = pathtest.rstrip('/')
    wav_files = glob.glob(path_wav + '/*.wav')
    IEMOCAP_LABEL = {
        '01': 0,
        '04': 1,
        '05': 2,
        '07': 3,
    }
    for wavtest in wav_files:
        wavname = wavtest[22:]
        label = str(os.path.basename(wavtest).split('-')[2])
        label = IEMOCAP_LABEL[label]
        wav_data, _ = librosa.load(wavtest, sr=RATE)
        X1 = []
        index = 0
        if len(wav_data) < t * RATE:
            A = np.zeros((t * RATE))
            A[: len(wav_data)] = wav_data
            X1.append(A)
        elif (index + t * RATE <= len(wav_data)):
            X1.append(wav_data[int(index):int(index + t * RATE)])
        X1 = np.array(X1)
        feature_extractor = FeatureExtractor(rate=RATE)
        X_1 = feature_extractor.get_features(FEATURES_TO_USE, X1)
        X_1_NEXT = feature_extractor.get_features(FEATURES_TO_USE_NEXT, X1)
        X_1 = torch.tensor(X_1).unsqueeze(1).cuda()
        X_1_NEXT = torch.tensor(X_1_NEXT).unsqueeze(1).cuda()
        model = Parallel_Model.CNN_Transformer(4)
        model.load_state_dict(torch.load(pthpath))
        if torch.cuda.is_available():
            model = model.cuda()
        # with torch.nn_grad():
        _, outputs = model(X_1.float(),X_1_NEXT.float())
              # 正向传播
        max_value, max_idx = torch.max(outputs, dim=1)
        if max_idx[-1] == label:
            with open(jsonpath) as f_obj:
                m = f_obj.readlines()
                mm = m[0]  # 获取了json文件中的list列表
                new_list = literal_eval(mm)
                new_list[wavname] +=1
                with open(jsonpath, "w") as w:
                    w.write(str(new_list))



# 测试类
def test(tt):
    with open(tt) as f_obj:
        m = f_obj.readlines()
        mm = m[0]  # 获取了json文件中的list列表
        new_list = literal_eval(mm)
        print(type(new_list))


test_path = "D:\\allemotionwav\\test/"
dict_test_path = "test_dict.json"
RATE=16000
t = 5
Epchos = 20
FEATURES_TO_USE = 'logfbank'  # {'mfcc' , 'logfbank','fbank','spectrogram','melspectrogram'} Features used for cnn
FEATURES_TO_USE_NEXT = 'mfcc'
MODEL_PATH = 'models/parallel_model_5_{}.pth'.format(Epchos)
# createjson(test_path, dict_test_path)
wavpth(test_path, MODEL_PATH, dict_test_path)
# test(dict_test_path)
